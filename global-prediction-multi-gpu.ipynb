{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import pandas as pd\n",
    "import jax\n",
    "import jraph\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('/n/holystore01/LABS/iaifi_lab/Lab/set-diffuser-data/val_split/')\n",
    "halos = jnp.load(data_dir / 'train_halos.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n"
     ]
    }
   ],
   "source": [
    "cosmology = pd.read_csv(data_dir / f'train_cosmology.csv')\n",
    "print(len(cosmology))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Omega_m</th>\n",
       "      <th>Omega_b</th>\n",
       "      <th>h</th>\n",
       "      <th>n_s</th>\n",
       "      <th>sigma_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1755</td>\n",
       "      <td>0.06681</td>\n",
       "      <td>0.7737</td>\n",
       "      <td>0.8849</td>\n",
       "      <td>0.6641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.05557</td>\n",
       "      <td>0.8599</td>\n",
       "      <td>0.9785</td>\n",
       "      <td>0.8619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1867</td>\n",
       "      <td>0.04503</td>\n",
       "      <td>0.6189</td>\n",
       "      <td>0.8307</td>\n",
       "      <td>0.7187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Omega_m  Omega_b       h     n_s  sigma_8\n",
       "0   0.1755  0.06681  0.7737  0.8849   0.6641\n",
       "1   0.2139  0.05557  0.8599  0.9785   0.8619\n",
       "2   0.1867  0.04503  0.6189  0.8307   0.7187"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosmology.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega_m = jnp.array(cosmology['Omega_m'].values)[:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train EGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax\n",
    "from flax.training.train_state import TrainState\n",
    "from functools import partial\n",
    "import flax.linen as nn\n",
    "import optax\n",
    "from tqdm import trange\n",
    "\n",
    "replicate = flax.jax_utils.replicate\n",
    "unreplicate = flax.jax_utils.unreplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.graph_utils import build_graph\n",
    "from models.egnn import EGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphWrapper(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        model = jax.vmap(EGNN(n_outputs=1,\n",
    "                              message_passing_steps=4,\n",
    "                              n_layers=2,\n",
    "                              d_hidden=128,\n",
    "                              activation='gelu',\n",
    "                              positions_only=True, \n",
    "                              use_fourier_features=True,\n",
    "                              tanh_out=False))  # Actually seems to inhibit learning in this case...\n",
    "        return model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "halo_pos = halos[...,:3] / 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 20\n",
    "use_pbc = False\n",
    "use_edges = False\n",
    "\n",
    "graph = build_graph(halo_pos[:5], k=k, use_pbc=use_pbc, use_edges=use_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphWrapper()\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "out, params = model.init_with_output(key, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 GPUs available\n"
     ]
    }
   ],
   "source": [
    "# Devices\n",
    "num_local_devices = jax.local_device_count()\n",
    "print(f\"{num_local_devices} GPUs available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train state and replicate across devices\n",
    "tx = optax.adamw(learning_rate=3e-4, weight_decay=1e-5)\n",
    "state = TrainState.create(apply_fn=model.apply, params=params, tx=tx)\n",
    "pstate = replicate(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_mse(pred_batch, cosmo_batch,):\n",
    "    return jnp.mean((pred_batch - cosmo_batch) ** 2)\n",
    "\n",
    "@partial(jax.pmap, axis_name=\"batch\",)\n",
    "def train_step(state, halo_batch, cosmo_batch,):\n",
    "\n",
    "    # Build graph\n",
    "    halo_graph = build_graph(halo_batch, k=k, use_pbc=use_pbc, use_edges=use_edges)\n",
    "    \n",
    "    def loss_fn(params):\n",
    "        outputs = state.apply_fn(params, halo_graph)\n",
    "        loss = loss_mse(outputs, cosmo_batch)\n",
    "        return loss\n",
    "\n",
    "    # Get loss, grads, and update state\n",
    "    loss, grads = jax.value_and_grad(loss_fn)(state.params)\n",
    "    grads = jax.lax.pmean(grads, \"batch\")\n",
    "    new_state = state.apply_gradients(grads=grads)\n",
    "    metrics = {\"loss\": jax.lax.pmean(loss, \"batch\")}\n",
    "    \n",
    "    return new_state, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████| 1000/1000 [01:42<00:00,  9.72it/s, loss=0.00015028678]\n"
     ]
    }
   ],
   "source": [
    "n_steps = 1000\n",
    "n_batch = 32\n",
    "\n",
    "with trange(n_steps) as steps:\n",
    "    for step in steps:\n",
    "        key, subkey = jax.random.split(key)\n",
    "        idx = jax.random.choice(key, halo_pos.shape[0], shape=(n_batch,))\n",
    "        \n",
    "        # halo_batch, cosmo_batch = halo_pos[idx], omega_m[idx]\n",
    "        halo_batch, cosmo_batch = halo_pos[:n_batch], omega_m[:n_batch]  # Overfit on a small sample\n",
    "\n",
    "        # Split batches across devices\n",
    "        halo_batch = jax.tree_map(lambda x: np.split(x, num_local_devices, axis=0), halo_batch)\n",
    "        cosmo_batch = jax.tree_map(lambda x: np.split(x, num_local_devices, axis=0), cosmo_batch)\n",
    "        halo_batch, cosmo_batch = np.array(halo_batch), np.array(cosmo_batch)\n",
    "\n",
    "        pstate, metrics = train_step(pstate, halo_batch, cosmo_batch)\n",
    "        \n",
    "        steps.set_postfix(loss=unreplicate(metrics[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = n_batch\n",
    "\n",
    "graph = build_graph(halo_pos[:n_test], k=k, use_pbc=use_pbc, use_edges=use_edges)\n",
    "omega_m_pred = model.apply(unreplicate(pstate).params, graph)\n",
    "print(omega_m_pred.shape)\n",
    "\n",
    "plt.scatter(omega_m[:n_test], omega_m_pred[:,0], s=5)\n",
    "plt.plot(omega_m[:n_test], omega_m[:n_test], color='gray')\n",
    "\n",
    "plt.xlabel(\"True\")\n",
    "plt.ylabel(\"Predicted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
