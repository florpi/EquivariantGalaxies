{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-10 20:10:09.571180: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-10 20:10:09.571738: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-10 20:10:09.612450: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>vx</th>\n",
       "      <th>vy</th>\n",
       "      <th>vz</th>\n",
       "      <th>Jx</th>\n",
       "      <th>Jy</th>\n",
       "      <th>Jz</th>\n",
       "      <th>M200c</th>\n",
       "      <th>Rvir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>523.87921</td>\n",
       "      <td>997.09070</td>\n",
       "      <td>329.35129</td>\n",
       "      <td>-58.62</td>\n",
       "      <td>429.58</td>\n",
       "      <td>121.10</td>\n",
       "      <td>-7.548000e+17</td>\n",
       "      <td>5.696000e+17</td>\n",
       "      <td>-9.084000e+17</td>\n",
       "      <td>4051300000000000</td>\n",
       "      <td>3264.635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>832.85913</td>\n",
       "      <td>388.96509</td>\n",
       "      <td>288.60141</td>\n",
       "      <td>575.17</td>\n",
       "      <td>1124.71</td>\n",
       "      <td>638.53</td>\n",
       "      <td>-9.456000e+17</td>\n",
       "      <td>-2.231000e+17</td>\n",
       "      <td>4.367000e+17</td>\n",
       "      <td>3363200000000000</td>\n",
       "      <td>3161.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>931.41461</td>\n",
       "      <td>481.97626</td>\n",
       "      <td>815.59155</td>\n",
       "      <td>6.48</td>\n",
       "      <td>139.10</td>\n",
       "      <td>20.07</td>\n",
       "      <td>-3.455000e+17</td>\n",
       "      <td>-3.971000e+15</td>\n",
       "      <td>3.417000e+17</td>\n",
       "      <td>3023700000000000</td>\n",
       "      <td>2941.829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>830.04327</td>\n",
       "      <td>74.93627</td>\n",
       "      <td>536.11200</td>\n",
       "      <td>653.95</td>\n",
       "      <td>41.30</td>\n",
       "      <td>-186.97</td>\n",
       "      <td>-1.212000e+17</td>\n",
       "      <td>1.092000e+18</td>\n",
       "      <td>-8.631000e+16</td>\n",
       "      <td>2881700000000000</td>\n",
       "      <td>2889.544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>245.69009</td>\n",
       "      <td>977.35895</td>\n",
       "      <td>225.14355</td>\n",
       "      <td>781.71</td>\n",
       "      <td>162.50</td>\n",
       "      <td>181.48</td>\n",
       "      <td>-2.718000e+15</td>\n",
       "      <td>7.374000e+17</td>\n",
       "      <td>6.526000e+17</td>\n",
       "      <td>2784700000000000</td>\n",
       "      <td>2836.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>259.89481</td>\n",
       "      <td>331.97177</td>\n",
       "      <td>943.88849</td>\n",
       "      <td>589.36</td>\n",
       "      <td>-189.89</td>\n",
       "      <td>-11.83</td>\n",
       "      <td>4.858000e+15</td>\n",
       "      <td>2.160000e+16</td>\n",
       "      <td>-1.090000e+15</td>\n",
       "      <td>342250000000000</td>\n",
       "      <td>1462.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>851.34479</td>\n",
       "      <td>954.74152</td>\n",
       "      <td>351.61807</td>\n",
       "      <td>-123.16</td>\n",
       "      <td>-530.66</td>\n",
       "      <td>171.77</td>\n",
       "      <td>-3.083000e+16</td>\n",
       "      <td>1.434000e+16</td>\n",
       "      <td>-7.996000e+15</td>\n",
       "      <td>342250000000000</td>\n",
       "      <td>1421.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>398.50443</td>\n",
       "      <td>974.74878</td>\n",
       "      <td>164.84859</td>\n",
       "      <td>572.37</td>\n",
       "      <td>578.25</td>\n",
       "      <td>611.00</td>\n",
       "      <td>4.723000e+15</td>\n",
       "      <td>-1.924000e+16</td>\n",
       "      <td>3.721000e+16</td>\n",
       "      <td>342250000000000</td>\n",
       "      <td>1458.534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>841.52911</td>\n",
       "      <td>938.93311</td>\n",
       "      <td>396.58209</td>\n",
       "      <td>952.90</td>\n",
       "      <td>-270.64</td>\n",
       "      <td>-439.37</td>\n",
       "      <td>8.968000e+15</td>\n",
       "      <td>7.282000e+15</td>\n",
       "      <td>6.092000e+15</td>\n",
       "      <td>342250000000000</td>\n",
       "      <td>1461.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>727.48419</td>\n",
       "      <td>356.03589</td>\n",
       "      <td>6.97011</td>\n",
       "      <td>-42.77</td>\n",
       "      <td>-248.74</td>\n",
       "      <td>-78.78</td>\n",
       "      <td>4.030000e+16</td>\n",
       "      <td>-5.975000e+15</td>\n",
       "      <td>-5.928000e+16</td>\n",
       "      <td>342250000000000</td>\n",
       "      <td>1455.470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x          y          z      vx       vy      vz            Jx  \\\n",
       "0     523.87921  997.09070  329.35129  -58.62   429.58  121.10 -7.548000e+17   \n",
       "1     832.85913  388.96509  288.60141  575.17  1124.71  638.53 -9.456000e+17   \n",
       "2     931.41461  481.97626  815.59155    6.48   139.10   20.07 -3.455000e+17   \n",
       "3     830.04327   74.93627  536.11200  653.95    41.30 -186.97 -1.212000e+17   \n",
       "4     245.69009  977.35895  225.14355  781.71   162.50  181.48 -2.718000e+15   \n",
       "...         ...        ...        ...     ...      ...     ...           ...   \n",
       "4995  259.89481  331.97177  943.88849  589.36  -189.89  -11.83  4.858000e+15   \n",
       "4996  851.34479  954.74152  351.61807 -123.16  -530.66  171.77 -3.083000e+16   \n",
       "4997  398.50443  974.74878  164.84859  572.37   578.25  611.00  4.723000e+15   \n",
       "4998  841.52911  938.93311  396.58209  952.90  -270.64 -439.37  8.968000e+15   \n",
       "4999  727.48419  356.03589    6.97011  -42.77  -248.74  -78.78  4.030000e+16   \n",
       "\n",
       "                Jy            Jz             M200c      Rvir  \n",
       "0     5.696000e+17 -9.084000e+17  4051300000000000  3264.635  \n",
       "1    -2.231000e+17  4.367000e+17  3363200000000000  3161.956  \n",
       "2    -3.971000e+15  3.417000e+17  3023700000000000  2941.829  \n",
       "3     1.092000e+18 -8.631000e+16  2881700000000000  2889.544  \n",
       "4     7.374000e+17  6.526000e+17  2784700000000000  2836.105  \n",
       "...            ...           ...               ...       ...  \n",
       "4995  2.160000e+16 -1.090000e+15   342250000000000  1462.600  \n",
       "4996  1.434000e+16 -7.996000e+15   342250000000000  1421.951  \n",
       "4997 -1.924000e+16  3.721000e+16   342250000000000  1458.534  \n",
       "4998  7.282000e+15  6.092000e+15   342250000000000  1461.585  \n",
       "4999 -5.975000e+15 -5.928000e+16   342250000000000  1455.470  \n",
       "\n",
       "[5000 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/n/holystore01/LABS/iaifi_lab/Lab/quijote_bsq/halos_1234.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = np.loadtxt('/n/holystore01/LABS/iaifi_lab/Lab/quijote_bsq/BSQ_params.txt')\n",
    "params.shape\n",
    "\n",
    "params_names = ['Omega_m', 'Omega_b', 'h', 'n_s', 'sigma_8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing TFRecord 1 / 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1818/1818 [00:32<00:00, 56.63it/s]\n",
      "Writing TFRecord 2 / 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1818/1818 [00:25<00:00, 72.49it/s]\n",
      "Writing TFRecord 3 / 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1818/1818 [00:24<00:00, 74.36it/s]\n",
      "Writing TFRecord 4 / 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1818/1818 [00:26<00:00, 67.51it/s]\n",
      "Writing TFRecord 5 / 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1818/1818 [00:27<00:00, 66.38it/s]\n",
      "Writing TFRecord 6 / 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1818/1818 [01:22<00:00, 22.11it/s]\n",
      "Writing TFRecord 7 / 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1818/1818 [01:51<00:00, 16.33it/s]\n",
      "Writing TFRecord 8 / 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1818/1818 [01:47<00:00, 16.96it/s]\n",
      "Writing TFRecord 9 / 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1818/1818 [01:50<00:00, 16.41it/s]\n",
      "Writing TFRecord 10 / 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1809/1809 [01:46<00:00, 16.97it/s]\n"
     ]
    }
   ],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def serialize_example(features, params):\n",
    "    \"\"\"\n",
    "    Creates a tf.train.Example message ready to be written to a file.\n",
    "    \"\"\"\n",
    "    \n",
    "    feature = {k: _bytes_feature(tf.io.serialize_tensor(tf.cast(v, tf.float32)).numpy()) for k, v in features.items()}\n",
    "    # feature['params'] = _bytes_feature(tf.io.serialize_tensor(tf.cast(params, tf.float32)).numpy())\n",
    "\n",
    "    # Params contains 5 values, pick individual values and save using params_names as the key, similar to features above\n",
    "    for i, param in enumerate(params):\n",
    "        feature[params_names[i]] = _bytes_feature(tf.io.serialize_tensor(tf.cast(param, tf.float32)).numpy()) \n",
    "\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()\n",
    "\n",
    "params_ary = np.loadtxt('/n/holystore01/LABS/iaifi_lab/Lab/quijote_bsq/BSQ_params.txt')\n",
    "\n",
    "def process_csv_to_tfrecords(csv_files_path, tfrecords_path, num_tfrecords=10, num_tfrecords_val=1):\n",
    "    \"\"\"\n",
    "    Converts CSV files in a folder to a specified number of TFRecord files.\n",
    "    \"\"\"\n",
    "\n",
    "    # Make tfrecords_path if it doesn't exist\n",
    "    os.makedirs(tfrecords_path, exist_ok=True)\n",
    "\n",
    "    csv_files = [os.path.join(csv_files_path, f) for f in os.listdir(csv_files_path) if f.endswith('.csv')]\n",
    "    num_files = len(csv_files)\n",
    "    files_per_tfrecord = int(np.ceil(num_files / num_tfrecords))\n",
    "    \n",
    "    for i in range(num_tfrecords):\n",
    "        tfrecord_file = os.path.join(tfrecords_path, f'halos_train_{i + 1}.tfrecord' if i < num_tfrecords - num_tfrecords_val else f'halos_val_{i + 1 - (num_tfrecords - num_tfrecords_val)}.tfrecord')\n",
    "        with tf.io.TFRecordWriter(tfrecord_file) as writer:\n",
    "            subset_csv_files = csv_files[i * files_per_tfrecord:(i + 1) * files_per_tfrecord]\n",
    "            for csv_file in tqdm(subset_csv_files, desc=f'Writing TFRecord {i + 1} / {num_tfrecords}'):\n",
    "                df = pd.read_csv(csv_file)\n",
    "\n",
    "                # Get index of csv file, format halos_{index}.csv\n",
    "                idx = int(csv_file.split('_')[-1].split('.')[0])\n",
    "                \n",
    "                features = {col: df[col] for col in df.columns if col != 'id'}\n",
    "                example = serialize_example(features, params_ary[idx])\n",
    "                writer.write(example)\n",
    "\n",
    "csv_files_path = '/n/holystore01/LABS/iaifi_lab/Lab/quijote_bsq'\n",
    "tfrecords_path = '/n/holystore01/LABS/iaifi_lab/Lab/quijote_bsq_tfrecords'\n",
    "num_tfrecords = 10  # Specify the number of TFRecord files you want\n",
    "num_tfrecords_val = 1  # Specify the number of TFRecord files you want for validation\n",
    "\n",
    "process_csv_to_tfrecords(csv_files_path, tfrecords_path, num_tfrecords, num_tfrecords_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(proto, features=['x', 'y', 'z', 'Jx', 'Jy', 'Jz', 'vx', 'vy', 'vz', 'M200c'], \n",
    "                    params=['Omega_m', 'Omega_b', 'h', 'n_s', 'sigma_8']):\n",
    "    \n",
    "    # Define your tfrecord again. It must match with how you wrote it\n",
    "    keys_to_features = {k: tf.io.FixedLenFeature([], tf.string) for k in features}\n",
    "    keys_to_params = {k: tf.io.FixedLenFeature([], tf.string) for k in params}\n",
    "    \n",
    "    # Load one example\n",
    "    parsed_features = tf.io.parse_single_example(proto, keys_to_features)\n",
    "    parsed_params = tf.io.parse_single_example(proto, keys_to_params)\n",
    "\n",
    "    # Convert each feature from a serialized string to a tensor and store in a list\n",
    "    feature_tensors = [tf.io.parse_tensor(parsed_features[k], out_type=tf.float32) for k in features]\n",
    "    param_tensors = [tf.io.parse_tensor(parsed_params[k], out_type=tf.float32) for k in params]\n",
    "\n",
    "    # Stack the feature tensors to create a single tensor\n",
    "    # Each tensor must have the same shape\n",
    "    stacked_features = tf.stack(feature_tensors, axis=1)  # Creates a [num_points, num_features] tensor\n",
    "    stacked_params = tf.stack(param_tensors, axis=0)  # Creates a [num_params] tensor\n",
    "\n",
    "    return stacked_features, stacked_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def get_halo_dataset(batch_size=64, features=['x', 'y', 'z', 'Jx', 'Jy', 'Jz', 'vx', 'vy', 'vz', 'M200c', 'Rvir'],\n",
    "                     params=['Omega_m', 'sigma_8']):\n",
    "\n",
    "    files = tf.io.gfile.glob(f\"/n/holystore01/LABS/iaifi_lab/Lab/quijote_bsq_tfrecords/halos*.tfrecord\")\n",
    "    dataset = tf.data.TFRecordDataset(files)\n",
    "    num_total = sum(1 for _ in dataset)\n",
    "    dataset = dataset.map(partial(_parse_function, features=features, params=params))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    return dataset, num_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 5000, 11]), TensorShape([64, 5]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=['x', 'y', 'z', 'Jx', 'Jy', 'Jz', 'vx', 'vy', 'vz', 'M200c', 'Rvir']\n",
    "params=['Omega_m', 'Omega_b', 'h', 'n_s', 'sigma_8']\n",
    "batch_size = 64\n",
    "\n",
    "dataset, num_total = get_halo_dataset(batch_size=64, features=features, params=params)\n",
    "iterator = iter(dataset)\n",
    "\n",
    "x, params = next(iterator)\n",
    "x.shape, params.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 283/283 [00:02<00:00, 113.54it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 283/283 [00:02<00:00, 117.63it/s]\n"
     ]
    }
   ],
   "source": [
    "iterator = iter(dataset)\n",
    "\n",
    "# First pass: Compute the mean\n",
    "mean = 0\n",
    "mean_params = 0\n",
    "for i in tqdm(range(num_total // batch_size)):\n",
    "    batch, batch_params = next(iterator)\n",
    "    batch = tf.cast(batch, tf.float64)\n",
    "    mean += tf.reduce_mean(batch, axis=(0, 1))\n",
    "    mean_params += tf.reduce_mean(batch_params, axis=0)\n",
    "mean /= (num_total // batch_size)\n",
    "mean_params /= (num_total // batch_size)\n",
    "\n",
    "# Reset the iterator for the second pass\n",
    "iterator = iter(dataset)\n",
    "\n",
    "# Second pass: Compute the variance, then standard deviation\n",
    "variance = 0\n",
    "variance_params = 0\n",
    "for i in tqdm(range(num_total // batch_size)):\n",
    "    batch, batch_params = next(iterator)\n",
    "    batch = tf.cast(batch, tf.float64)\n",
    "    variance += tf.reduce_mean(tf.square(batch - mean), axis=(0, 1))\n",
    "    variance_params += tf.reduce_mean(tf.square(batch_params - mean_params), axis=0)\n",
    "variance /= (num_total // batch_size)\n",
    "variance_params /= (num_total // batch_size)\n",
    "\n",
    "std = tf.sqrt(variance)\n",
    "std_params = tf.sqrt(variance_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dict mapping feature names to mean and std\n",
    "MEAN_HALOS_DICT = {f: m for f, m in zip(features, mean.numpy())}\n",
    "STD_HALOS_DICT = {f: s for f, s in zip(features, std.numpy())}\n",
    "\n",
    "MEAN_PARAMS_DICT = {f: m for f, m in zip(params_names, mean_params.numpy())}\n",
    "STD_PARAMS_DICT = {f: s for f, s in zip(params_names, std_params.numpy())}\n",
    "\n",
    "# MEAN_HALOS_DICT, STD_HALOS_DICT, MEAN_PARAMS_DICT, STD_PARAMS_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 16362\n"
     ]
    }
   ],
   "source": [
    "from dataset.dataset import get_halo_dataset\n",
    "\n",
    "features = ['x', 'y', 'z', 'vx', 'vy', 'vz', 'M200c']\n",
    "params = ['Omega_m', 'sigma_8']\n",
    "batch_size = 64\n",
    "\n",
    "dataset, num_total = get_halo_dataset(batch_size=batch_size, \n",
    "                           num_samples=None,  # If not None, will only take a subset of the dataset\n",
    "                           standardize=True,  # If True, will standardize the features\n",
    "                           return_mean_std=False,  # If True, will return (dataset, num_total, mean, std, mean_params, std_params), else (dataset, num_total)\n",
    "                           seed=42,\n",
    "                           features=features, \n",
    "                           params=params)\n",
    "\n",
    "# Print number of samples\n",
    "print(f\"Number of samples: {num_total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/255 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "iterator = iter(dataset)\n",
    "\n",
    "for _ in tqdm(range(num_total // batch_size)):\n",
    "    x, params = next(iterator)\n",
    "\n",
    "x.shape, params.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 5000, 7]), TensorShape([64, 2]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "equivariant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
